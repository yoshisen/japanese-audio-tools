{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9844d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisperで日本語音声を認識しLRCファイルを生成する\n",
    "#このノートブックはGoogle Colab上でGPUを使って日本語音声を処理し、\n",
    "# タイムスタンプ付きのLRC歌詞ファイルを生成するためのものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 必要なライブラリをインストール\n",
    "!pip install -q openai-whisper\n",
    "!pip install -q torch torchvision torchaudio\n",
    "\n",
    "# GPUが利用可能か確認\n",
    "import torch\n",
    "print(f\"CUDA 利用可能: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU デバイス: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f8085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 必要なライブラリをインポート\n",
    "import whisper\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    \"\"\"秒数をLRC形式のタイムスタンプ [mm:ss.xx] に変換\"\"\"\n",
    "    td = timedelta(seconds=seconds)\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    minutes = total_seconds // 60\n",
    "    seconds = total_seconds % 60\n",
    "    centiseconds = int((td.total_seconds() - total_seconds) * 100)\n",
    "    return f\"[{minutes:02d}:{seconds:02d}.{centiseconds:02d}]\"\n",
    "\n",
    "def generate_lrc(segments, output_path):\n",
    "    \"\"\"Whisperの分割結果からLRCファイルを生成\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        # LRCファイルのヘッダーを書き込む\n",
    "        f.write(\"[ar:Unknown]\\n\")\n",
    "        f.write(\"[ti:Unknown]\\n\")\n",
    "        f.write(\"[by:Whisper AI]\\n\")\n",
    "        f.write(\"[00:00.00]\\n\")\n",
    "        \n",
    "        # 各行の歌詞とタイムスタンプを書き込む\n",
    "        for segment in segments:\n",
    "            timestamp = format_timestamp(segment['start'])\n",
    "            text = segment['text'].strip()\n",
    "            f.write(f\"{timestamp}{text}\\n\")\n",
    "    \n",
    "    print(f\"LRCファイルが生成されました: {output_path}\")\n",
    "\n",
    "print(\"関数定義完了!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f584b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Whisperモデルを読み込む\n",
    "# 選択可能なモデル: tiny / base / small / medium / large\n",
    "# 日本語認識には medium または large モデルを推奨（高精度）\n",
    "# GPUメモリが不足する場合は small か base を選択\n",
    "\n",
    "model_size = \"medium\"  # 必要に応じて変更\n",
    "print(f\"Whisper {model_size} モデルを読み込んでいます...\")\n",
    "model = whisper.load_model(model_size)\n",
    "print(f\"モデルの読み込みが完了しました! 使用デバイス: {model.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 音声ファイルをアップロード（Colab想定）\n",
    "from google.colab import files\n",
    "\n",
    "print(\"音声ファイルをアップロードしてください...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# アップロードしたファイル名を取得\n",
    "audio_file = list(uploaded.keys())[0]\n",
    "print(f\"アップロード済みファイル: {audio_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bdeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Whisperで日本語音声を認識\n",
    "print(\"音声の認識を開始します...\")\n",
    "print(\"これには数分かかる場合があります。音声の長さとモデルのサイズによります...\")\n",
    "\n",
    "# GPUで転写し、言語を日本語に指定\n",
    "result = model.transcribe(\n",
    "    audio_file,\n",
    "    language=\"ja\",  # 言語に日本語を指定\n",
    "    verbose=True,   # 進捗を表示\n",
    "    task=\"transcribe\"  # 転写タスク\n",
    ")\n",
    "\n",
    "print(\"\\n認識完了!\")\n",
    "print(f\"検出された言語: {result['language']}\")\n",
    "print(f\"テキスト: {result['text'][:100]}...\")  # 先頭100文字を表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4583c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. LRCファイルを生成\n",
    "# 出力ファイル名を設定\n",
    "lrc_filename = os.path.splitext(audio_file)[0] + \".lrc\"\n",
    "\n",
    "# LRCファイルを作成\n",
    "generate_lrc(result['segments'], lrc_filename)\n",
    "\n",
    "# 先頭数行をプレビュー\n",
    "print(\"\\nLRCファイルのプレビュー:\")\n",
    "with open(lrc_filename, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:10]:  # 先頭10行を表示\n",
    "        print(line.rstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4bab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. LRCファイルをダウンロード（Colab想定）\n",
    "from google.colab import files\n",
    "\n",
    "print(f\"LRCファイルをダウンロード: {lrc_filename}\")\n",
    "files.download(lrc_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d676b1d",
   "metadata": {},
   "source": [
    "## オプション：複数の音声ファイルを一括処理\n",
    "\n",
    "複数の音声ファイルを処理する必要がある場合は、以下のコードを使用できます：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ処理用の関数\n",
    "import glob\n",
    "\n",
    "def process_audio_to_lrc(audio_path, model, output_dir=\"./\"):\n",
    "    \"\"\"\n",
    "    単一の音声ファイルを処理してLRCファイルを生成\n",
    "    \n",
    "    パラメータ:\n",
    "        audio_path: 音声ファイルのパス\n",
    "        model: 読み込み済みのWhisperモデル\n",
    "        output_dir: 出力ディレクトリ\n",
    "    \"\"\"\n",
    "    print(f\"\\nファイルを処理中: {audio_path}\")\n",
    "    \n",
    "    try:\n",
    "        # 音声を認識\n",
    "        result = model.transcribe(\n",
    "            audio_path,\n",
    "            language=\"ja\",\n",
    "            verbose=False,\n",
    "            task=\"transcribe\"\n",
    "        )\n",
    "        \n",
    "        # LRCファイルを作成\n",
    "        filename = os.path.basename(audio_path)\n",
    "        lrc_filename = os.path.splitext(filename)[0] + \".lrc\"\n",
    "        lrc_path = os.path.join(output_dir, lrc_filename)\n",
    "        \n",
    "        generate_lrc(result['segments'], lrc_path)\n",
    "        print(f\"✓ 完了: {lrc_filename}\")\n",
    "        return lrc_path\n",
    "    except Exception as e:\n",
    "        print(f\"✗ エラー: {audio_path} - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def batch_process_folder(folder_path, model, output_dir=None):\n",
    "    \"\"\"\n",
    "    指定したフォルダ内のすべての音声ファイルを一括処理\n",
    "    \n",
    "    パラメータ:\n",
    "        folder_path: 音声ファイルが含まれるフォルダのパス\n",
    "        model: 読み込み済みのWhisperモデル\n",
    "        output_dir: 出力ディレクトリ（Noneの場合は元のフォルダに出力）\n",
    "    \"\"\"\n",
    "    # 出力フォルダが未指定なら入力フォルダを使う\n",
    "    if output_dir is None:\n",
    "        output_dir = folder_path\n",
    "    \n",
    "    # 出力フォルダが無ければ作成\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 対応する音声フォーマット\n",
    "    audio_extensions = ['*.mp3', '*.wav', '*.m4a', '*.flac', '*.ogg', '*.aac', '*.wma']\n",
    "    \n",
    "    # すべての音声ファイルを取得\n",
    "    audio_files = []\n",
    "    for ext in audio_extensions:\n",
    "        pattern = os.path.join(folder_path, ext)\n",
    "        audio_files.extend(glob.glob(pattern))\n",
    "        # 拡張子の大文字も検索\n",
    "        pattern_upper = os.path.join(folder_path, ext.upper())\n",
    "        audio_files.extend(glob.glob(pattern_upper))\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(f\"フォルダ '{folder_path}' 内に音声ファイルが見つかりませんでした\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"{len(audio_files)} 個の音声ファイルが見つかりました\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 各ファイルを処理\n",
    "    results = []\n",
    "    for i, audio_file in enumerate(audio_files, 1):\n",
    "        print(f\"\\n[{i}/{len(audio_files)}] 処理中...\")\n",
    "        lrc_path = process_audio_to_lrc(audio_file, model, output_dir)\n",
    "        if lrc_path:\n",
    "            results.append(lrc_path)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"一括処理完了! 成功: {len(results)}/{len(audio_files)}\")\n",
    "    return results\n",
    "\n",
    "print(\"一括処理関数が定義されました!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a920738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 一括処理: 音声を含むZIPをアップロード\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "print(\"音声ファイルを含むZIP圧縮ファイルをアップロードしてください...\")\n",
    "uploaded_zip = files.upload()\n",
    "\n",
    "if uploaded_zip:\n",
    "    # アップロードしたZIPのファイル名を取得\n",
    "    zip_filename = list(uploaded_zip.keys())[0]\n",
    "    \n",
    "    # 展開先ディレクトリを作成\n",
    "    extract_dir = \"audio_files\"\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    \n",
    "    # ファイルを解凍\n",
    "    print(f\"\\n{zip_filename} を解凍しています...\")\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    \n",
    "    print(f\"ファイルは次の場所に解凍されました: {extract_dir}\")\n",
    "    \n",
    "    # 展開したファイルを表示\n",
    "    print(\"\\n解凍されたファイル:\")\n",
    "    for root, dirs, files in os.walk(extract_dir):\n",
    "        for file in files:\n",
    "            print(f\"  - {os.path.join(root, file)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. バッチ処理を実行\n",
    "# 処理対象のフォルダパスを指定\n",
    "input_folder = \"audio_files\"  # 自分のフォルダパスに変更\n",
    "output_folder = \"lrc_output\"  # LRCファイルの出力先\n",
    "\n",
    "# バッチ処理を開始\n",
    "print(f\"フォルダの一括処理を開始: {input_folder}\")\n",
    "print(f\"LRCファイルの保存先: {output_folder}\\n\")\n",
    "\n",
    "lrc_files = batch_process_folder(input_folder, model, output_folder)\n",
    "\n",
    "print(f\"\\n生成されたLRCファイル:\")\n",
    "for lrc_file in lrc_files:\n",
    "    print(f\"  - {lrc_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 生成したLRCファイルをZIPにまとめてダウンロード\n",
    "import shutil\n",
    "\n",
    "# ZIPファイルを作成\n",
    "output_zip = \"lrc_files.zip\"\n",
    "print(f\"LRCファイルをパッケージングしています...\")\n",
    "\n",
    "shutil.make_archive(\n",
    "    output_zip.replace('.zip', ''),  # 拡張子なしのファイル名\n",
    "    'zip',                            # 圧縮形式\n",
    "    output_folder                     # 圧縮対象のフォルダ\n",
    ")\n",
    "\n",
    "print(f\"パッケージング完了: {output_zip}\")\n",
    "\n",
    "# ZIPファイルをダウンロード\n",
    "from google.colab import files\n",
    "files.download(output_zip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e970ffe",
   "metadata": {},
   "source": [
    "## 使用説明\n",
    "\n",
    "### 単一ファイルの処理フロー\n",
    "1. **依存関係をインストール**：1番目のコードセルを実行して必要なライブラリをインストール\n",
    "2. **ライブラリをインポートして関数を定義**：2番目のコードセルを実行\n",
    "3. **モデルを読み込む**：3番目のコードセルを実行（モデルサイズを変更可能）\n",
    "   - `tiny`: 最速、精度は低め\n",
    "   - `base`: 高速、精度は普通\n",
    "   - `small`: 速度と精度のバランス\n",
    "   - `medium`: やや遅い、精度高い（日本語推奨）\n",
    "   - `large`: 最も遅い、最も精度が高い\n",
    "4. **音声をアップロード**：4番目のコードセルを実行して音声ファイルをアップロード\n",
    "5. **音声を認識**：5番目のコードセルを実行して認識開始\n",
    "6. **LRCを生成**：6番目のコードセルを実行してLRCファイルを生成\n",
    "7. **ファイルをダウンロード**：7番目のコードセルを実行して生成されたLRCファイルをダウンロード\n",
    "\n",
    "### バッチ処理フロー（推奨）\n",
    "1. **依存関係をインストール**：1番目のコードセルを実行\n",
    "2. **ライブラリをインポートして関数を定義**：2番目のコードセルを実行\n",
    "3. **モデルを読み込む**：3番目のコードセルを実行\n",
    "4. **一括処理関数を定義**：9番目のコードセル（「オプション：一括処理」セクション）を実行\n",
    "5. **圧縮ファイルをアップロード**：10番目のコードセルを実行し、すべての音声ファイルを含むZIP圧縮ファイルをアップロード\n",
    "6. **一括処理**：11番目のコードセルを実行し、フォルダ内のすべての音声ファイルを自動処理\n",
    "7. **結果をダウンロード**：12番目のコードセルを実行し、パッケージ化されたすべてのLRCファイルをダウンロード\n",
    "\n",
    "**対応する音声フォーマット**: MP3, WAV, M4A, FLAC, OGG, AAC, WMA など\n",
    "\n",
    "**一括処理の利点**：\n",
    "- フォルダ内のすべての音声ファイルを自動認識\n",
    "- 複数の音声フォーマットに対応\n",
    "- 自動的に出力ディレクトリを作成\n",
    "- 処理進捗と成功率を表示\n",
    "- エラー処理機能付き、1つのファイルが失敗しても他のファイルに影響なし\n",
    "- 生成されたすべてのLRCファイルをパッケージ化してダウンロード可能\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
